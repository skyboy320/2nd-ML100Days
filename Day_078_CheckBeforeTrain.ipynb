{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "### 學習在模型開始前檢查各個環節\n",
    "1. 是否有 GPU 資源\n",
    "2. 將前處理轉為函式，統一處理訓練、驗證與測試集\n",
    "3. 將超參數變數化，易於重複使用函式、模型等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA System Management Interface -- v425.31\n",
      "\n",
      "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
      "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
      "NVSMI also provides several management operations for changing the device state.\n",
      "\n",
      "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
      "library. See the NVIDIA developer website for more information about NVML.\n",
      "Python wrappers to NVML are also available.  The output of NVSMI is\n",
      "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
      "compatible.\n",
      "\n",
      "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
      "http://pypi.python.org/pypi/nvidia-ml-py/\n",
      "Supported products:\n",
      "- Full Support\n",
      "    - All Tesla products, starting with the Kepler architecture\n",
      "    - All Quadro products, starting with the Kepler architecture\n",
      "    - All GRID products, starting with the Kepler architecture\n",
      "    - GeForce Titan products, starting with the Kepler architecture\n",
      "- Limited Support\n",
      "    - All Geforce products, starting with the Kepler architecture\n",
      "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
      "\n",
      "    -h,   --help                Print usage information and exit.\n",
      "\n",
      "  LIST OPTIONS:\n",
      "\n",
      "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
      "\n",
      "    -B,   --list-blacklist-gpus Display a list of blacklisted GPUs in the system.\n",
      "\n",
      "  SUMMARY OPTIONS:\n",
      "\n",
      "    <no arguments>              Show a summary of GPUs connected to the system.\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "\n",
      "  QUERY OPTIONS:\n",
      "\n",
      "    -q,   --query               Display GPU or Unit info.\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -x,   --xml-format          Produce XML output.\n",
      "          --dtd                 When showing xml output, embed DTD.\n",
      "    -d,   --display=            Display only selected information: MEMORY,\n",
      "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
      "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
      "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS, FBC_STATS\n",
      "                                Flags can be combined with comma e.g. ECC,POWER.\n",
      "                                Sampling data with max/min/avg is also returned \n",
      "                                for POWER, UTILIZATION and CLOCK display types.\n",
      "                                Doesn't work with -u or -x flags.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
      "\n",
      "  SELECTIVE QUERY OPTIONS:\n",
      "\n",
      "    Allows the caller to pass an explicit list of properties to query.\n",
      "\n",
      "    [one of]\n",
      "\n",
      "    --query-gpu=                Information about GPU.\n",
      "                                Call --help-query-gpu for more info.\n",
      "    --query-supported-clocks=   List of supported clocks.\n",
      "                                Call --help-query-supported-clocks for more info.\n",
      "    --query-compute-apps=       List of currently active compute processes.\n",
      "                                Call --help-query-compute-apps for more info.\n",
      "    --query-accounted-apps=     List of accounted compute processes.\n",
      "                                Call --help-query-accounted-apps for more info.\n",
      "    --query-retired-pages=      List of device memory pages that have been retired.\n",
      "                                Call --help-query-retired-pages for more info.\n",
      "\n",
      "    [mandatory]\n",
      "\n",
      "    --format=                   Comma separated list of format options:\n",
      "                                  csv - comma separated values (MANDATORY)\n",
      "                                  noheader - skip the first line with column headers\n",
      "                                  nounits - don't print units for numerical\n",
      "                                             values\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
      "\n",
      "  DEVICE MODIFICATION OPTIONS:\n",
      "\n",
      "    [any one of]\n",
      "\n",
      "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
      "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
      "    -c,   --compute-mode=       Set MODE for compute applications:\n",
      "                                0/DEFAULT, 1/EXCLUSIVE_PROCESS,\n",
      "                                2/PROHIBITED\n",
      "    -dm,  --driver-model=       Enable or disable TCC mode: 0/WDDM, 1/TCC\n",
      "    -fdm, --force-driver-model= Enable or disable TCC mode: 0/WDDM, 1/TCC\n",
      "                                Ignores the error that display is connected.\n",
      "          --gom=                Set GPU Operation Mode:\n",
      "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
      "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
      "                                    pair (e.g. 1500,1500) that defines the range \n",
      "                                    of desired locked GPU clock speed in MHz.\n",
      "                                    Setting this will supercede application clocks\n",
      "                                    and take effect regardless if an app is running.\n",
      "                                    Input can also be a singular desired clock value\n",
      "                                    (e.g. <GpuClockValue>).\n",
      "    -rgc  --reset-gpu-clocks\n",
      "                                Resets the Gpu clocks to the default values.\n",
      "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
      "                                    pair (e.g. 2000,800) that defines GPU's\n",
      "                                    speed in MHz while running applications on a GPU.\n",
      "    -rac  --reset-applications-clocks\n",
      "                                Resets the applications clocks to the default values.\n",
      "    -acp  --applications-clocks-permission=\n",
      "                                Toggles permission requirements for -ac and -rac commands:\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\n",
      "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
      "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
      "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
      "                                Only on supported devices starting from the Volta series.\n",
      "                                Requires administrator privileges.\n",
      "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
      "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
      "    -caa  --clear-accounted-apps\n",
      "                                Clears all the accounted PIDs in the buffer.\n",
      "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
      "                                or 1/ENABLED, enforcing the change only after the\n",
      "                                last boost client has exited.\n",
      "          --auto-boost-permission=\n",
      "                                Allow non-admin/root control over auto boost mode:\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\n",
      "   [plus optional]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU.\n",
      "\n",
      "  UNIT MODIFICATION OPTIONS:\n",
      "\n",
      "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
      "\n",
      "   [plus optional]\n",
      "\n",
      "    -i,   --id=                 Target a specific Unit.\n",
      "\n",
      "  SHOW DTD OPTIONS:\n",
      "\n",
      "          --dtd                 Print device DTD and exit.\n",
      "\n",
      "     [plus optional]\n",
      "\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -u,   --unit                Show unit, rather than device, DTD.\n",
      "\n",
      "    --debug=                    Log encrypted debug information to a specified file. \n",
      "\n",
      " Device Monitoring:\n",
      "    dmon                        Displays device stats in scrolling format.\n",
      "                                \"nvidia-smi dmon -h\" for more information.\n",
      "\n",
      "    daemon                      Runs in background and monitor devices as a daemon process.\n",
      "                                This is an experimental feature. Not supported on Windows baremetal\n",
      "                                \"nvidia-smi daemon -h\" for more information.\n",
      "\n",
      "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
      "                                This is an experimental feature.\n",
      "                                \"nvidia-smi replay -h\" for more information.\n",
      "\n",
      " Process Monitoring:\n",
      "    pmon                        Displays process stats in scrolling format.\n",
      "                                \"nvidia-smi pmon -h\" for more information.\n",
      "\n",
      " NVLINK:\n",
      "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
      "\n",
      " CLOCKS:\n",
      "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
      "\n",
      " ENCODER SESSIONS:\n",
      "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
      "\n",
      " FBC SESSIONS:\n",
      "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
      "\n",
      "Please see the nvidia-smi documentation for more detailed information.\n"
     ]
    }
   ],
   "source": [
    "## 確認硬體資源 (如果你是在 Linux, 若是在 Windows, 請參考 https://blog.csdn.net/idwtwt/article/details/78017565)\n",
    "!nvidia-smi -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 11:53:22.993131 13224 deprecation_wrapper.py:119] From C:\\Users\\Trenton\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0811 11:53:23.030040 13224 deprecation_wrapper.py:119] From C:\\Users\\Trenton\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0811 11:53:23.035021 13224 deprecation_wrapper.py:119] From C:\\Users\\Trenton\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp(input_shape=x_train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 12:25:26.498044 13224 deprecation.py:323] From C:\\Users\\Trenton\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0811 12:25:26.626520 13224 deprecation_wrapper.py:119] From C:\\Users\\Trenton\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(256, 3072), b.shape=(3072, 512), m=256, n=512, k=3072\n\t [[{{node hidden_layer1/MatMul}}]]\n\t [[loss_1/mul/_113]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(256, 3072), b.shape=(3072, 512), m=256, n=512, k=3072\n\t [[{{node hidden_layer1/MatMul}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2b6128154f9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Blas GEMM launch failed : a.shape=(256, 3072), b.shape=(3072, 512), m=256, n=512, k=3072\n\t [[{{node hidden_layer1/MatMul}}]]\n\t [[loss_1/mul/_113]]\n  (1) Internal: Blas GEMM launch failed : a.shape=(256, 3072), b.shape=(3072, 512), m=256, n=512, k=3072\n\t [[{{node hidden_layer1/MatMul}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-923aa18fddb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "# 訓練模型並檢視驗證集的結果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請嘗試將 preproc_x 替換成以每筆資料的 min/max 進行標準化至 -1 ~ 1 間，再進行訓練\n",
    "2. 請嘗試將 mlp 疊更深 (e.g 5~10 層)，進行訓練後觀察 learning curve 的走勢\n",
    "3. (optional) 請改用 GPU 進行訓練 (如果你有 GPU 的話)，比較使用 CPU 與 GPU 的訓練速度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
